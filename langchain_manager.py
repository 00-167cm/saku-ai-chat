"""
ğŸ”µ langchain_managerã®å½¹å‰²
    AIã¨ã®é€£æº(ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…¥åŠ›æ¸¡ã™ã“ã¨ã‹ã‚‰ã€AIã®è¿”ç­”è¿”ã™ã¾ã§)
    chat_managerã‹ã‚‰å—ã‘å–ã£ãŸãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…¥åŠ›ã‚’AIã«æ¸¡ã™
    AIã®å›ç­”ã‚’å–å¾—
    AIã®å›ç­”ã‚’chat_managerã«è¿”ã™
    ä¼šè©±å†…å®¹ã‹ã‚‰ã‚¿ã‚¤ãƒˆãƒ«ã‚’ç”Ÿæˆ
    
ã€æ›´æ–°å±¥æ­´ã€‘
- RAGãƒ¢ãƒ¼ãƒ‰ç”¨ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¨ãƒ¬ã‚¹ãƒãƒ³ã‚¹ç”Ÿæˆã‚’è¿½åŠ 
"""
# LangChainã®OpenAIæ¥ç¶šã‚¯ãƒ©ã‚¹
from langchain_openai import ChatOpenAI
# ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç®¡ç†
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
# å‡ºåŠ›ã‚’æ–‡å­—åˆ—ã«å¤‰æ›
from langchain_core.output_parsers import StrOutputParser
# ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å‹
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage
# å‹ãƒ’ãƒ³ãƒˆç”¨
from typing import List, Generator


class LangChainManager:
    """
    LangChainã‚’ä½¿ã£ãŸAIé€£æºã‚’ç®¡ç†ã™ã‚‹ã‚¯ãƒ©ã‚¹
    åˆæœŸåŒ–ã—ãŸæ™‚ã«å¼•æ•°ã‚’ä¸ãˆã¦ã„ãªã„ã‹ã‚‰ã€model,temperatureã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå¼•æ•°ãŒé©ç”¨ã•ã‚Œã‚‹

    """
    def __init__(self, model: str = "gpt-4o-mini", temperature: float = 0.7):
        """
        LangChainã®åˆæœŸåŒ–
        
        OpenAIã¨ã®æ¥ç¶šæº–å‚™å®Œäº†
        ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆä½œæˆå®Œäº†
        AIã«é€ä¿¡ã§ãã‚‹çŠ¶æ…‹ã«ãªã£ãŸ

        ã€å‡¦ç†ã®æµã‚Œã€‘
        1. å¼•æ•°ã§å—ã‘å–ã£ãŸmodel, temperatureã‚’ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹å¤‰æ•°ã«ä¿å­˜
        2. LLM(ChatOpenAI)ã‚’åˆæœŸåŒ–
        3. ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ä½œæˆ
        4. å‡ºåŠ›ãƒ‘ãƒ¼ã‚µãƒ¼ã‚’åˆæœŸåŒ–
        5. ã“ã‚Œã‚‰ã‚’çµ„ã¿åˆã‚ã›ã¦ãƒã‚§ãƒ¼ãƒ³ã‚’ä½œæˆ
        
        Args:
            model: ä½¿ç”¨ã™ã‚‹OpenAIãƒ¢ãƒ‡ãƒ«
            temperature: ç”Ÿæˆã®å¤šæ§˜æ€§(0.0-1.0)
        """
        # ã€å‡¦ç†ã®æµã‚Œã€‘
        # 1.å¼•æ•°ã‚’ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹å¤‰æ•°ã«æ ¼ç´
        self.model = model
        self.temperature = temperature

        # é–¢æ•°åã®é ­ã«ã¤ãã€Œ_ã€ã¯ãã®ã‚¯ãƒ©ã‚¹å†…ã‹ã‚‰ã—ã‹å‘¼ã³å‡ºã•ã‚Œãªã„ã“ã¨ã‚’è¡¨ã™ãƒãƒŠãƒ¼(ãƒ«ãƒ¼ãƒ«ã§ã¯ãªã„)
        # 2._initialize_llm() ã‚’å‘¼ã³å‡ºã—ã¦LLMã‚’åˆæœŸåŒ–
        self.llm = self._initialize_llm()
        # â†’ ChatOpenAI(model="gpt-4o-mini", temperature=0.7) ãŒå®Ÿè¡Œã•ã‚Œã‚‹
        # â†’ OpenAIã«æ¥ç¶šã§ãã‚‹çŠ¶æ…‹ã«ãªã‚‹

        # 3. ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ä½œæˆ
        self.prompt = self._create_prompt()
        # â†’ ChatPromptTemplate.from_messages([...]) ãŒå®Ÿè¡Œã•ã‚Œã‚‹
        # â†’ ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¨MessagesPlaceholderãŒè¨­å®šã•ã‚Œã‚‹

        # 4. å‡ºåŠ›ãƒ‘ãƒ¼ã‚µãƒ¼ã‚’åˆæœŸåŒ–(AIã®å¿œç­”ã‚’æ–‡å­—åˆ—ã«å¤‰æ›ã™ã‚‹ãŸã‚ã®ã‚‚ã®)
        self.output_parser = StrOutputParser()
        # 5. ã“ã‚Œã‚‰ã‚’çµ„ã¿åˆã‚ã›ã¦ãƒã‚§ãƒ¼ãƒ³ã‚’ä½œæˆ(prompt â†’ llm â†’ output_parser ã®é †ã§å‡¦ç†ãŒæµã‚Œã‚‹)
        # |(ãƒ‘ã‚¤ãƒ—)æ¼”ç®—å­ã§ã¤ãªãã“ã¨ã§ã€ãƒ‡ãƒ¼ã‚¿ãŒé †ç•ªã«æµã‚Œã¦ã„ã
        self.chain = self.prompt | self.llm | self.output_parser
        
        # ã‚¿ã‚¤ãƒˆãƒ«ç”Ÿæˆç”¨ã®ãƒã‚§ãƒ¼ãƒ³ã‚‚ä½œæˆ
        self.title_prompt = self._create_title_prompt()
        self.title_chain = self.title_prompt | self.llm | self.output_parser
        
        # ğŸ†• RAGç”¨ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¨ãƒã‚§ãƒ¼ãƒ³ã‚’ä½œæˆ
        self.rag_prompt = self._create_rag_prompt()
        self.rag_chain = self.rag_prompt | self.llm | self.output_parser
    
    def _initialize_llm(self) -> ChatOpenAI:
        """
        LLM(Large Language Model)ã®åˆæœŸåŒ–

        ã€å‡¦ç†å†…å®¹ã€‘
        - ChatOpenAIã‚¯ãƒ©ã‚¹ã‚’ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹åŒ–
        - self.modelã¨self.temperatureã‚’ä½¿ã£ã¦AIã¨ã®æ¥ç¶šã‚’è¨­å®š
        
        ã€æˆ»ã‚Šå€¤ã€‘
        ChatOpenAIã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹(AIã¨ã®æ¥ç¶šã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ)
        
        ã€è£œè¶³ã€‘
        -> ChatOpenAI ã¯ã€Œã“ã®é–¢æ•°ã®æˆ»ã‚Šå€¤ã®å‹ã€ã‚’ç¤ºã™å‹ãƒ’ãƒ³ãƒˆ
        å®Ÿéš›ã®å‹•ä½œã«ã¯å½±éŸ¿ã—ãªã„ãŒã€ã‚³ãƒ¼ãƒ‰ã‚’èª­ã‚€äººã«åˆ†ã‹ã‚Šã‚„ã™ãã™ã‚‹ãŸã‚
        """
        return ChatOpenAI(
            model=self.model,
            temperature=self.temperature
        )
    
    def _create_prompt(self) -> ChatPromptTemplate:
        # ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹åŒ–ã—ãŸChatPromptTemplateã‚’è¿”ã™ã€Œã ã‘ã€
        # ã‚¯ãƒ©ã‚¹ã®ä¸­ã«é–¢æ•°ãŒã‚ã‚‹      
        """
        ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã®ä½œæˆ
        ã€å‡¦ç†å†…å®¹ã€‘
        - ChatPromptTemplate.from_messages()ã‚’å‘¼ã³å‡ºã—ã¦ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ä½œæˆ
        - ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ(AIã®æ€§æ ¼è¨­å®š)ã¨ä¼šè©±å±¥æ­´ã®å ´æ‰€ã‚’å®šç¾©
        
        ã€æˆ»ã‚Šå€¤ã€‘
        ChatPromptTemplateã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹

        ã€è£œè¶³ã€‘
        ã‚¯ãƒ©ã‚¹ã®ä¸­ã«ã‚ã‚‹é–¢æ•°(ãƒ¡ã‚½ãƒƒãƒ‰)ã‚’å‘¼ã³å‡ºã™æ–¹æ³•:
        
        æ–¹æ³•â‘ : ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹åŒ–ã—ã¦ã‹ã‚‰å‘¼ã³å‡ºã™
            instance = ClassName()
            instance.method_name()
        
        æ–¹æ³•â‘¡: ã‚¯ãƒ©ã‚¹ã‹ã‚‰ç›´æ¥å‘¼ã³å‡ºã™(ã‚¯ãƒ©ã‚¹ãƒ¡ã‚½ãƒƒãƒ‰ã®å ´åˆ)
            ClassName.method_name()
        
        ä»Šå›ã¯æ–¹æ³•â‘¡ã‚’ä½¿ã£ã¦ã„ã‚‹
            ChatPromptTemplate.from_messages() ã¯ã‚¯ãƒ©ã‚¹ãƒ¡ã‚½ãƒƒãƒ‰
        
        """
        return ChatPromptTemplate.from_messages([
            (
                "system",
                "ã‚ãªãŸã¯ãƒ•ãƒ¬ãƒ³ãƒ‰ãƒªãƒ¼ã§è¦ªåˆ‡ãªAIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«å¯¾ã—ã¦ã€æ˜ã‚‹ãã‚ã‹ã‚Šã‚„ã™ãä¸å¯§ã«ç­”ãˆã¦ãã ã•ã„ã€‚"
            ),
            MessagesPlaceholder(variable_name="messages")
        ])
    
    def _create_title_prompt(self) -> ChatPromptTemplate:
        """
        ã‚¿ã‚¤ãƒˆãƒ«ç”Ÿæˆç”¨ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ä½œæˆ
        
        ã€å‡¦ç†å†…å®¹ã€‘
        - ä¼šè©±å†…å®¹ã‚’è¦ç´„ã—ã¦ã‚¿ã‚¤ãƒˆãƒ«ã‚’ç”Ÿæˆã™ã‚‹ãŸã‚ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
        - 12æ–‡å­—ä»¥å†…ã¨ã„ã†åˆ¶ç´„ã‚’è¨­å®š
        
        ã€æˆ»ã‚Šå€¤ã€‘
        ChatPromptTemplateã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
        """
        return ChatPromptTemplate.from_messages([
            (
                "system",
                """ä»¥ä¸‹ã®ä¼šè©±å†…å®¹ã‚’è¦ç´„ã—ã¦ã€12æ–‡å­—ä»¥å†…ã®çŸ­ã„ã‚¿ã‚¤ãƒˆãƒ«ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚
                
ãƒ«ãƒ¼ãƒ«:
- 12æ–‡å­—ä»¥å†…ã§ç°¡æ½”ã«
- ä¼šè©±ã®ä¸»è¦ãªãƒ†ãƒ¼ãƒã‚’æ‰ãˆã‚‹
- ã€Œã€œã«ã¤ã„ã¦ã€ãªã©ã®ä½™è¨ˆãªè¨€è‘‰ã¯çœã
- ã‚¿ã‚¤ãƒˆãƒ«ã®ã¿ã‚’å‡ºåŠ›(èª¬æ˜æ–‡ã¯ä¸è¦)

ä¾‹:
ä¼šè©±: Pythonã®åŸºæœ¬æ–‡æ³•ã«ã¤ã„ã¦æ•™ãˆã¦ â†’ ã‚¿ã‚¤ãƒˆãƒ«: Pythonæ–‡æ³•
ä¼šè©±: ãŠã™ã™ã‚ã®ã‚«ãƒ•ã‚§ã‚’æ•™ãˆã¦ â†’ ã‚¿ã‚¤ãƒˆãƒ«: ãŠã™ã™ã‚ã‚«ãƒ•ã‚§
ä¼šè©±: ã‚¹ãƒˆãƒ¬ã‚¹è§£æ¶ˆæ³•ã«ã¤ã„ã¦ â†’ ã‚¿ã‚¤ãƒˆãƒ«: ã‚¹ãƒˆãƒ¬ã‚¹è§£æ¶ˆ"""
            ),
            MessagesPlaceholder(variable_name="messages")
        ])
    
    def _create_rag_prompt(self) -> ChatPromptTemplate:
        """
        ğŸ†• RAGç”¨ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ä½œæˆ
        
        ã€å‡¦ç†å†…å®¹ã€‘
        - å‚ç…§è³‡æ–™ã‚’åŸºã«å›ç­”ã™ã‚‹ãŸã‚ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
        - NSCãƒ­ãƒ¼ã‚«ãƒ«ãƒ«ãƒ¼ãƒ«ã«å¾“ã£ãŸå›ç­”å½¢å¼ã‚’æŒ‡å®š
        
        ã€æˆ»ã‚Šå€¤ã€‘
        ChatPromptTemplateã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
        """
        return ChatPromptTemplate.from_messages([
            (
                "system",
                """ã‚ãªãŸã¯ã‚¢ã‚³ãƒ  ãƒãƒƒãƒˆã‚µãƒ¼ãƒ“ã‚¹ã‚»ãƒ³ã‚¿ãƒ¼ã®æ¥­å‹™ã‚µãƒãƒ¼ãƒˆAIã§ã™ã€‚

ã€é‡è¦ãªãƒ«ãƒ¼ãƒ«ã€‘
1. å›ç­”ã®å†’é ­ã«ã€ŒNSCæ¥­å‹™ãƒ•ãƒ­ãƒ¼ã«åŸºã¥ãã€ã¾ãŸã¯ã€Œãƒãƒƒãƒˆã‚µãƒ¼ãƒ“ã‚¹ã‚»ãƒ³ã‚¿ãƒ¼ã®ãƒ­ãƒ¼ã‚«ãƒ«ãƒ«ãƒ¼ãƒ«ã«ã‚ˆã‚‹ã¨ã€ã¨ã„ã†æ¥é ­èªã‚’ä»˜ã‘ã¦ãã ã•ã„
2. å‚ç…§è³‡æ–™ã«æ›¸ã‹ã‚Œã¦ã„ã‚‹æƒ…å ±ã®ã¿ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„
3. å‚ç…§è³‡æ–™ã«ãªã„æƒ…å ±ã¯ã€Œè³‡æ–™ã«è¨˜è¼‰ãŒã‚ã‚Šã¾ã›ã‚“ã€ã¨æ­£ç›´ã«ä¼ãˆã¦ãã ã•ã„
4. å…·ä½“çš„ãªã‚³ãƒ¼ãƒ‰åã‚„ãƒ«ãƒ¼ãƒ«åï¼ˆNSCã‚³ãƒ¼ãƒ‰ã€NGç†ç”±ã‚³ãƒ¼ãƒ‰è¡¨ãªã©ï¼‰ãŒã‚ã‚‹å ´åˆã¯ã€ãã‚Œã‚’æ˜è¨˜ã—ã¦ãã ã•ã„
5. åˆ†ã‹ã‚Šã‚„ã™ãã€ä¸å¯§ã«å›ç­”ã—ã¦ãã ã•ã„

å‚ç…§è³‡æ–™ãŒã‚ã‚‹å ´åˆã¯ã€ãã‚Œã«åŸºã¥ã„ã¦å›ç­”ã—ã¾ã™ã€‚"""
            ),
            MessagesPlaceholder(variable_name="messages")
        ])
    
    def create_human_message(self, content: str) -> HumanMessage:
        """
        ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…¥åŠ›ã‹ã‚‰HumanMessageã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ä½œæˆ
        
        ã€å‡¦ç†å†…å®¹ã€‘
        - æ–‡å­—åˆ—ã‚’LangChainã®HumanMessageå‹ã«å¤‰æ›
        - LangChainã¯ã“ã®å‹ã‚’ä½¿ã£ã¦ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ç®¡ç†
        
        Args:
            content: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆ(ä¾‹: "ã“ã‚“ã«ã¡ã¯")
        
        Returns:
            HumanMessage: LangChainç”¨ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
        
        ã€å‘¼ã³å‡ºã—ä¾‹ã€‘
        message = langchain_manager.create_human_message("ã“ã‚“ã«ã¡ã¯")
        # messageã¯ HumanMessage(content="ã“ã‚“ã«ã¡ã¯") ã¨ã„ã†å½¢ã«ãªã‚‹
        """
        return HumanMessage(content=content)
    
    def create_ai_message(self, content: str) -> AIMessage:
        """
        AIã®å¿œç­”ã‹ã‚‰AIMessageã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ä½œæˆ
        
        ã€å‡¦ç†å†…å®¹ã€‘
        - æ–‡å­—åˆ—ã‚’LangChainã®AIMessageå‹ã«å¤‰æ›
        - LangChainã¯ã“ã®å‹ã‚’ä½¿ã£ã¦AIã®å¿œç­”ã‚’ç®¡ç†
        
        Args:
            content: AIã®å¿œç­”ãƒ†ã‚­ã‚¹ãƒˆ(ä¾‹: "ã“ã‚“ã«ã¡ã¯!èª¿å­ã¯ã©ã†?")
        
        Returns:
            AIMessage: LangChainç”¨ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
        
        ã€å‘¼ã³å‡ºã—ä¾‹ã€‘
        message = langchain_manager.create_ai_message("ã“ã‚“ã«ã¡ã¯!")
        # messageã¯ AIMessage(content="ã“ã‚“ã«ã¡ã¯!") ã¨ã„ã†å½¢ã«ãªã‚‹
        """
        # AIMessageã‚¯ãƒ©ã‚¹ã‚’ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹åŒ–
        # contentã‚’å¼•æ•°ã¨ã—ã¦æ¸¡ã™ã¨ã€AIã®å¿œç­”ã¨ã—ã¦æ‰±ã‚ã‚Œã‚‹
        return AIMessage(content=content)
    
    def get_streaming_response(
        self,
        messages: List
    ) -> Generator[str, None, None]:
        """
        ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å±¥æ­´ã‚’åŸºã«AIã‹ã‚‰ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å¿œç­”ã‚’å–å¾—
        
        ã€å‡¦ç†å†…å®¹ã€‘
        1. self.chain.stream()ã§AIã«ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’é€ã‚‹
        2. AIã‹ã‚‰1æ–‡å­—ãšã¤(ãƒãƒ£ãƒ³ã‚¯ã”ã¨ã«)å¿œç­”ãŒè¿”ã£ã¦ãã‚‹
        3. yieldã§1ã¤ãšã¤è¿”ã™(ã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ãƒ¼é–¢æ•°)
        
        Args:
            messages: LangChainå½¢å¼ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å±¥æ­´ãƒªã‚¹ãƒˆ
                [HumanMessage(...), AIMessage(...), ...]
        
        Yields:
            str: AIã‹ã‚‰ã®å¿œç­”ãƒãƒ£ãƒ³ã‚¯(1æ–‡å­—ã€œæ•°æ–‡å­—ãšã¤)
        
        ã€Generatorã¨ã¯ã€‘
        Generator[str, None, None] ã¯å‹ãƒ’ãƒ³ãƒˆã§:
        - 1ã¤ç›®ã®str: yieldã§è¿”ã™å€¤ã®å‹
        - 2ã¤ç›®ã®None: send()ã§å—ã‘å–ã‚‹å€¤ã®å‹(ä»Šå›ã¯ä½¿ã‚ãªã„)
        - 3ã¤ç›®ã®None: return ã§è¿”ã™å€¤ã®å‹(ä»Šå›ã¯ä½¿ã‚ãªã„)
        
        ã€yieldã¨returnã®é•ã„ã€‘
        - return: å€¤ã‚’è¿”ã—ã¦é–¢æ•°çµ‚äº†
        - yield: å€¤ã‚’è¿”ã™ãŒé–¢æ•°ã¯ä¸€æ™‚åœæ­¢(æ¬¡ã®å‘¼ã³å‡ºã—ã§ç¶šãã‹ã‚‰å†é–‹)
        
        ã€å‘¼ã³å‡ºã—ä¾‹ã€‘
        for chunk in langchain_manager.get_streaming_response(messages):
            print(chunk)  # "ã“" "ã‚“" "ã«ã¡" "ã¯" ã®ã‚ˆã†ã«1ã¤ãšã¤è¡¨ç¤º
        """
        # self.chain.stream()ã§AIã«ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’é€ä¿¡
        # {"messages": messages} ã§ã€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®{messages}éƒ¨åˆ†ã«å±¥æ­´ã‚’åŸ‹ã‚è¾¼ã‚€
        for chunk in self.chain.stream({"messages": messages}):
            yield chunk
    
    def get_streaming_response_rag(
        self,
        messages: List
    ) -> Generator[str, None, None]:
        """
        ğŸ†• RAGãƒ¢ãƒ¼ãƒ‰ç”¨ã®ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å¿œç­”ã‚’å–å¾—
        
        ã€å‡¦ç†å†…å®¹ã€‘
        RAGç”¨ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ(rag_chain)ã‚’ä½¿ã£ã¦ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å¿œç­”ã‚’å–å¾—
        
        Args:
            messages: LangChainå½¢å¼ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å±¥æ­´ãƒªã‚¹ãƒˆ
                      ï¼ˆRAGãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å«ã‚€ï¼‰
        
        Yields:
            str: AIã‹ã‚‰ã®å¿œç­”ãƒãƒ£ãƒ³ã‚¯
        
        ã€å‘¼ã³å‡ºã—ä¾‹ã€‘
        for chunk in langchain_manager.get_streaming_response_rag(messages):
            print(chunk)
        """
        for chunk in self.rag_chain.stream({"messages": messages}):
            yield chunk
    
    def get_complete_response(
        self,
        messages: List
    ) -> str:
        """
        ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å±¥æ­´ã‚’åŸºã«AIã‹ã‚‰å®Œå…¨ãªå¿œç­”ã‚’å–å¾—
        (ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã§ã¯ãªãä¸€åº¦ã«å–å¾—)
        
        ã€å‡¦ç†å†…å®¹ã€‘
        - self.chain.invoke()ã§AIã«ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’é€ã‚‹
        - ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã›ãšã€å®Œæˆã—ãŸå¿œç­”ã‚’ä¸€æ°—ã«è¿”ã™
        
        Args:
            messages: LangChainå½¢å¼ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å±¥æ­´ãƒªã‚¹ãƒˆ
        
        Returns:
            str: AIã‹ã‚‰ã®å®Œå…¨ãªå¿œç­”(ä¾‹: "ã“ã‚“ã«ã¡ã¯!èª¿å­ã¯ã©ã†?")
        
        ã€get_streaming_response()ã¨ã®é•ã„ã€‘
        - get_streaming_response: 1æ–‡å­—ãšã¤è¿”ã™(ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ è¡¨ç¤ºå‘ã‘)
        - get_complete_response: å…¨æ–‡ã‚’ä¸€æ°—ã«è¿”ã™(ãƒãƒƒãƒå‡¦ç†å‘ã‘)
        
        ã€å‘¼ã³å‡ºã—ä¾‹ã€‘
        response = langchain_manager.get_complete_response(messages)
        print(response)  # "ã“ã‚“ã«ã¡ã¯!èª¿å­ã¯ã©ã†?" ã¨ä¸€æ°—ã«è¡¨ç¤º
        """
        return self.chain.invoke({"messages": messages})
    
    def generate_title(self, messages: List) -> str:
        """
        ä¼šè©±å†…å®¹ã‹ã‚‰ã‚¿ã‚¤ãƒˆãƒ«ã‚’ç”Ÿæˆ
        
        ã€å‡¦ç†å†…å®¹ã€‘
        1. ã‚¿ã‚¤ãƒˆãƒ«ç”Ÿæˆç”¨ã®ãƒã‚§ãƒ¼ãƒ³ã«ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’é€ã‚‹
        2. AIãŒä¼šè©±ã‚’è¦ç´„ã—ã¦ã‚¿ã‚¤ãƒˆãƒ«ã‚’è¿”ã™
        3. 15æ–‡å­—ã‚’è¶…ãˆãŸå ´åˆã¯åˆ‡ã‚Šè©°ã‚ã‚‹
        
        Args:
            messages: LangChainå½¢å¼ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å±¥æ­´ãƒªã‚¹ãƒˆ(æœ€åˆã®æ•°ä»¶)
        
        Returns:
            ç”Ÿæˆã•ã‚ŒãŸã‚¿ã‚¤ãƒˆãƒ«(15æ–‡å­—ä»¥å†…)
        
        ã€å‘¼ã³å‡ºã—ä¾‹ã€‘
        title = langchain_manager.generate_title(formatted_messages)
        # title = "PythonåŸºæœ¬æ–‡æ³•"
        """
        # ã‚¿ã‚¤ãƒˆãƒ«ç”Ÿæˆãƒã‚§ãƒ¼ãƒ³ã‚’å®Ÿè¡Œ
        title = self.title_chain.invoke({"messages": messages})
        
        # ä½™è¨ˆãªç©ºç™½ã‚„æ”¹è¡Œã‚’å‰Šé™¤
        title = title.strip()
        
        # 15æ–‡å­—ã‚’è¶…ãˆãŸå ´åˆã¯åˆ‡ã‚Šè©°ã‚ã‚‹
        if len(title) > 15:
            title = title[:15]
        
        return title
    
    def update_system_prompt(self, new_system_prompt: str):
        """
        ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ(AIã®æ€§æ ¼è¨­å®š)ã‚’æ›´æ–°
        
        ã€å‡¦ç†å†…å®¹ã€‘
        1. æ–°ã—ã„ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã§ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’å†ä½œæˆ
        2. ãƒã‚§ãƒ¼ãƒ³ã‚’å†æ§‹ç¯‰
        
        Args:
            new_system_prompt: æ–°ã—ã„ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
                            (ä¾‹: "ã‚ãªãŸã¯è¦ªåˆ‡ãªã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™")
        
        ã€ä½¿ç”¨ä¾‹ã€‘
        langchain_manager.update_system_prompt("ã‚ãªãŸã¯å³ã—ã„å…ˆç”Ÿã§ã™")
        # ã“ã®å¾Œã®AIå¿œç­”ã¯ã€Œå³ã—ã„å…ˆç”Ÿã€ã¨ã—ã¦æŒ¯ã‚‹èˆã†
        """
        # æ–°ã—ã„ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ä½œæˆ
        self.prompt = ChatPromptTemplate.from_messages([
            ("system", new_system_prompt),
            MessagesPlaceholder(variable_name="messages")
        ])
        # ãƒã‚§ãƒ¼ãƒ³ã‚’å†æ§‹ç¯‰
        self.chain = self.prompt | self.llm | self.output_parser
    
    def update_model_settings(
        self,
        model: str = None,
        temperature: float = None
    ):
        """
        ãƒ¢ãƒ‡ãƒ«è¨­å®šã‚’æ›´æ–°
        
        ã€å‡¦ç†å†…å®¹ã€‘
        1. modelã‚„temperatureãŒæŒ‡å®šã•ã‚Œã¦ã„ã‚Œã°æ›´æ–°
        2. LLMã‚’å†åˆæœŸåŒ–
        3. ãƒã‚§ãƒ¼ãƒ³ã‚’å†æ§‹ç¯‰
        
        Args:
            model: æ–°ã—ã„ãƒ¢ãƒ‡ãƒ«å(Noneãªã‚‰å¤‰æ›´ãªã—)
            temperature: æ–°ã—ã„temperatureå€¤(Noneãªã‚‰å¤‰æ›´ãªã—)
        
        ã€ä½¿ç”¨ä¾‹ã€‘
        # ãƒ¢ãƒ‡ãƒ«ã ã‘å¤‰æ›´
        langchain_manager.update_model_settings(model="gpt-4")
        
        # temperatureã ã‘å¤‰æ›´
        langchain_manager.update_model_settings(temperature=0.9)
        
        # ä¸¡æ–¹å¤‰æ›´
        langchain_manager.update_model_settings(model="gpt-4", temperature=0.5)
        """
        # modelãŒæŒ‡å®šã•ã‚Œã¦ã„ã‚Œã°(is not None)æ›´æ–°
        if model is not None:
            self.model = model
        # temperatureãŒæŒ‡å®šã•ã‚Œã¦ã„ã‚Œã°æ›´æ–°
        if temperature is not None:
            self.temperature = temperature
        
        # æ–°ã—ã„è¨­å®šã§LLMã‚’å†åˆæœŸåŒ–
        self.llm = self._initialize_llm()
        # ãƒã‚§ãƒ¼ãƒ³ã‚’å†æ§‹ç¯‰
        self.chain = self.prompt | self.llm | self.output_parser
        self.title_chain = self.title_prompt | self.llm | self.output_parser
        self.rag_chain = self.rag_prompt | self.llm | self.output_parser
